{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "REBER_GRAMMAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+nrtX99t3P1uYFuh2JdYU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinzus/miscellaneous/blob/main/REBER_GRAMMAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rfk6OBfMrNfd"
      },
      "source": [
        "\n",
        "IN THIS CODE I TRY TO SOLVE REBER GRAMMAR\n",
        "\n",
        "STEP 1: BUILD THE SIMPLE AND COMPLEX GENERATORS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxZ07i2TrI0R"
      },
      "source": [
        "# Import dependencies\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFwfrUF5rS_p"
      },
      "source": [
        "# add the character before!\n",
        "def rerun_short(st,go,alt):\n",
        "  no_prefix=0\n",
        "  while st.endswith(alt)==False:\n",
        "    proba=np.random.rand(1)\n",
        "    if proba>=.5:\n",
        "      st+=go\n",
        "    else:\n",
        "      st+=alt\n",
        "    no_prefix+=1\n",
        "  return st[-no_prefix:]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwCfBmQorS8d"
      },
      "source": [
        "def rerun_long(st,go_inside=\"t\",alt_inside=\"v\"):\n",
        "  begin=len(st)\n",
        "  while True:\n",
        "    st+=\"x\"\n",
        "    st+=rerun_short(st,go_inside,alt_inside)\n",
        "    proba_=np.random.rand(1)\n",
        "    if proba_>=.5:\n",
        "      st+=\"v\"\n",
        "      break    \n",
        "    else:\n",
        "      st+=\"p\"    \n",
        "  return st[begin:]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGba3DFnrS5T"
      },
      "source": [
        "# Reber grammar-simple generator\n",
        "def simple_generator():\n",
        "  z=\"b\"\n",
        "  proba_1=np.random.rand(1)\n",
        "  if proba_1>=.5:\n",
        "    z+=\"t\"\n",
        "    z+=rerun_short(z,\"s\",\"x\")\n",
        "    proba_2=np.random.rand(1)\n",
        "    if proba_2>=.5:\n",
        "      z+=\"se\"\n",
        "    else:\n",
        "      z+=rerun_long(z)\n",
        "      z+=\"e\"\n",
        "  else:\n",
        "    z+=\"p\"\n",
        "    z+=rerun_short(z,\"t\",\"v\")\n",
        "    proba_3=np.random.rand(1)\n",
        "    if proba_3>=.5: \n",
        "      z+=\"ve\"\n",
        "    else:\n",
        "      z+=\"p\"\n",
        "      z+=rerun_long(z)\n",
        "      z+=\"e\"\n",
        "  return z"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAT_UF9UrS2Z"
      },
      "source": [
        "# Reber grammar-complex generator\n",
        "def complex_generator():\n",
        "  z=\"b\"\n",
        "  proba=np.random.rand(1)\n",
        "  if proba>=.5:\n",
        "    z+=\"t\"\n",
        "    z+=simple_generator()\n",
        "    z+=\"te\"\n",
        "  else:\n",
        "    z+=\"p\"\n",
        "    z+=simple_generator()\n",
        "    z+=\"pe\"\n",
        "  return z"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulbcTf-mrSzn",
        "outputId": "a01b34e5-e75e-466c-eec0-ddbd58f2c509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "complex_generator()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bpbpvvepe'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOXqS0FWrxCO"
      },
      "source": [
        "STEP 2: CREATING THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkSvBiOoraKp"
      },
      "source": [
        "# Creating a fancy function for illegal words. With the permutations the newly generated set \n",
        "# is not granted to satisfy the grammar rules w.r.t. the order\n",
        "np.random.seed(12)\n",
        "a=simple_generator()\n",
        "k=[element for element in a]\n",
        "g=np.random.permutation(np.array(k))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPX0JQcNrafu"
      },
      "source": [
        "def complete_set(instances,generator):\n",
        "  max=0\n",
        "  for i in range(instances):\n",
        "    X_true_one=np.array([element for element in generator()])\n",
        "    X_false_one=np.random.permutation(X_true_one)\n",
        "    if len(X_true_one)>max:\n",
        "      max=len(X_true_one)\n",
        "    zero_padding_one=np.zeros((max-len(X_true_one)))\n",
        "    X_true_one=np.concatenate((X_true_one,zero_padding_one))\n",
        "    X_false_one=np.concatenate((X_false_one,zero_padding_one))\n",
        "    if i==0:\n",
        "      X_trues=X_true_one[tf.newaxis,:]\n",
        "      X_falses=X_false_one[tf.newaxis,:]\n",
        "    else:\n",
        "      X_true_one=X_true_one[tf.newaxis,:]\n",
        "      X_false_one=X_false_one[tf.newaxis,:]\n",
        "      if max>X_trues.shape[-1]:\n",
        "        zero_padding_two=np.zeros((len(X_trues),(max-X_trues.shape[-1])))\n",
        "        X_trues=np.concatenate((X_trues,zero_padding_two),axis=1)\n",
        "        X_falses=np.concatenate((X_falses,zero_padding_two),axis=1)\n",
        "      X_trues=np.concatenate((X_trues,X_true_one),axis=0)\n",
        "      X_falses=np.concatenate((X_falses,X_false_one),axis=0)\n",
        "      if i==instances-1:   # attach the labels at the end of the second axis\n",
        "        True_set=np.concatenate((X_trues,np.ones((instances,1))),axis=1)\n",
        "        False_set=np.concatenate((X_falses,np.zeros((instances,1))),axis=1)\n",
        "        return np.concatenate((True_set,False_set),axis=0)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qN7ZYtcrgJN"
      },
      "source": [
        "# NB: this cell is quite slow\n",
        "n_train=5000*2\n",
        "train=np.random.permutation(complete_set(5000,simple_generator))  # creating the dataset and shuffling it the first time"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCS2NFzmrid5"
      },
      "source": [
        "def preprocess(dataset):\n",
        "  global distinct\n",
        "  distinct=np.unique(dataset)\n",
        "  # Since we have only seven distinct characters, we can easily convert them manually to integers \n",
        "  new_dataset=np.empty(dataset.shape)\n",
        "  new_dataset=np.reshape(new_dataset,new_dataset.shape[0]*new_dataset.shape[1])\n",
        "  diction={\"0.0\":0,\"1.0\":1,\"b\":2,\"e\":3,\"p\":4,\"s\":5,\"t\":6,\"v\":7,\"x\":8}\n",
        "  for index,element in enumerate(np.reshape(dataset,dataset.shape[0]*dataset.shape[1])):\n",
        "    new_dataset[index]=diction[element]\n",
        "  return tf.constant(new_dataset.reshape(dataset.shape[0],dataset.shape[1]),dtype=tf.float32)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuyHMueurnE0"
      },
      "source": [
        "train=preprocess(train)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfiAJDAnrqyI"
      },
      "source": [
        "valid_=np.random.permutation(complete_set(2000,simple_generator))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUrKOf6Yrqdr"
      },
      "source": [
        "valid_=preprocess(valid_)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2NK_NEUry-l"
      },
      "source": [
        "\n",
        "STEP 3: GO TENSORFLOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vep2sApErqJL",
        "outputId": "71c0a2c3-c349-4103-f4cf-53539eae17a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train=tf.data.Dataset.from_tensor_slices(train)\n",
        "for i in train.take(1):\n",
        "  print(i.numpy())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 6. 8. 8. 6. 7. 7. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8gDptyZr1pc",
        "outputId": "439b41c1-73fc-4a34-db6e-06900be704a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size=16\n",
        "train=train.shuffle(500).repeat().batch(batch_size)\n",
        "train=train.map(lambda item:(item[:,:-1],item[:,-1:]))\n",
        "for item in train.take(1):\n",
        "  print(item)  # A tuple containing features and label\n",
        "train=train.prefetch(1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(16, 66), dtype=float32, numpy=\n",
            "array([[2., 4., 6., ..., 0., 0., 0.],\n",
            "       [2., 4., 7., ..., 0., 0., 0.],\n",
            "       [2., 6., 8., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [2., 6., 5., ..., 0., 0., 0.],\n",
            "       [2., 6., 5., ..., 0., 0., 0.],\n",
            "       [4., 6., 7., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
            "array([[1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.]], dtype=float32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4ikulazr58q",
        "outputId": "fcf07baa-1ef0-4768-b162-7916c3509c09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# for validation data:\n",
        "valid=tf.data.Dataset.from_tensor_slices(valid_)\n",
        "valid=valid.batch(batch_size)\n",
        "valid=valid.map(lambda item:(item[:,:-1],item[:,-1:]))\n",
        "valid.prefetch(1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 57), (None, 1)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ms3BF8Yr75E"
      },
      "source": [
        "def model_builder(n_units=128):\n",
        "  model=tf.keras.models.Sequential([\n",
        "          tf.keras.layers.Embedding(len(distinct),n_units,input_shape=[None],mask_zero=True),\n",
        "          tf.keras.layers.GRU(units=n_units),\n",
        "          tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "        ])\n",
        "  return model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJjfDJsir-hI",
        "outputId": "0ee19f0b-b7ee-48b0-f5ad-7709c6a634c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model=model_builder()\n",
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         1152      \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 100,353\n",
            "Trainable params: 100,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_lcgYqNsAXS",
        "outputId": "d5d1e720-0ff1-42fd-9785-dd66d22ba8a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "opt=tf.keras.optimizers.RMSprop(lr=.01)\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n",
        "history=model.fit(train,epochs=5,steps_per_epoch=n_train//batch_size,validation_data=valid)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 0.0173 - accuracy: 0.9972 - val_loss: 0.0258 - val_accuracy: 0.9967\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 0.0311 - accuracy: 0.9954 - val_loss: 0.0192 - val_accuracy: 0.9970\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 0.0149 - accuracy: 0.9979 - val_loss: 0.0233 - val_accuracy: 0.9965\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 38s 61ms/step - loss: 0.0169 - accuracy: 0.9976 - val_loss: 0.0185 - val_accuracy: 0.9970\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 38s 60ms/step - loss: 0.0142 - accuracy: 0.9983 - val_loss: 0.0178 - val_accuracy: 0.9973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzfI8O5_sDEP",
        "outputId": "f5defa39-bb9c-438b-b220-43e056076bb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# please feed a 2d array!\n",
        "inp=np.array([[\"b\",\"t\",\"s\",\"x\",\"x\",\"v\",\"v\",\"e\"]])\n",
        "if model.predict(preprocess(inp))>=.5:\n",
        "  print(\"Predicts LEGAL\")\n",
        "else:\n",
        "  print(\"Predicts ILLEGAL\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicts LEGAL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fnUrOZzsFYq",
        "outputId": "9102c0dd-82ae-487a-f7e2-d92b5d1710f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_valid_hat=[]\n",
        "all_preds=model.predict(valid)\n",
        "for k in all_preds:\n",
        "  if k>=.5:\n",
        "    X_valid_hat.append(1)\n",
        "  else:\n",
        "    X_valid_hat.append(0)\n",
        "\n",
        "\n",
        "confusion_matrix(valid_.numpy()[:,-1].astype(np.uint8),X_valid_hat)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1989,   11],\n",
              "       [   0, 2000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tSi3cD6sJ_X"
      },
      "source": [
        "\n",
        "STEP 4: FACE THE MORE COMPLEX ONE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJA7BFjasHrR"
      },
      "source": [
        "# NB: you can drink a coffee whilst waiting this to be executed\n",
        "n_train_1=7500*2\n",
        "train_1=np.random.permutation(complete_set(7500,complex_generator)) \n",
        "train_1=preprocess(train_1)\n",
        "valid_1_=np.random.permutation(complete_set(2000,complex_generator))\n",
        "valid_1_=preprocess(valid_1_)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajOVnmgksNh0"
      },
      "source": [
        "train_1=tf.data.Dataset.from_tensor_slices(train_1)\n",
        "train_1=train_1.shuffle(700).repeat().batch(batch_size)\n",
        "train_1=train_1.map(lambda item:(item[:,:-1],item[:,-1:]))\n",
        "train_1=train_1.prefetch(1)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrhV85sPsSNe"
      },
      "source": [
        "valid_1=tf.data.Dataset.from_tensor_slices(valid_1_)\n",
        "valid_1=valid_1.batch(batch_size)\n",
        "valid_1=valid_1.map(lambda item:(item[:,:-1],item[:,-1:]))\n",
        "valid_1=valid_1.prefetch(1)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubJH9UiisVpY"
      },
      "source": [
        "# Let's create with a model which is similar to the one used before\n",
        "def model_builder_1(n_units=128):\n",
        "  model=tf.keras.models.Sequential([\n",
        "          tf.keras.layers.Embedding(len(distinct),n_units,input_shape=[None],mask_zero=True),\n",
        "          tf.keras.layers.GRU(units=n_units),\n",
        "          tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "        ])\n",
        "  return model"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUfz36sPsX1F"
      },
      "source": [
        "model_1=model_builder_1()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSou-tiTsZsf",
        "outputId": "a073bbb0-3a66-4bdc-87de-26077ce1e997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "opt=tf.keras.optimizers.RMSprop(lr=.01)\n",
        "model_1.compile(loss=\"binary_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n",
        "history=model_1.fit(train_1,epochs=5,steps_per_epoch=n_train_1//batch_size,validation_data=valid_1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "937/937 [==============================] - 59s 63ms/step - loss: 0.0459 - accuracy: 0.9893 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
            "Epoch 2/5\n",
            "937/937 [==============================] - 60s 64ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
            "Epoch 3/5\n",
            "937/937 [==============================] - 60s 64ms/step - loss: 6.3227e-04 - accuracy: 0.9999 - val_loss: 3.9189e-09 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "937/937 [==============================] - 60s 64ms/step - loss: 3.3484e-09 - accuracy: 1.0000 - val_loss: 2.9716e-09 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "937/937 [==============================] - 58s 62ms/step - loss: 2.7231e-09 - accuracy: 1.0000 - val_loss: 2.5352e-09 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxsyppqdsdyg",
        "outputId": "599fe0e9-cf0a-4864-9853-bc0846bfc6a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inp1=np.array([[\"b\",\"t\",\"s\",\"x\",\"x\",\"v\",\"v\",\"e\"]])    # this was Legal in previous model!\n",
        "inp2=np.array([[\"b\",\"t\",\"b\",\"t\",\"s\",\"x\",\"x\",\"v\",\"v\",\"e\",\"t\",\"e\"]])\n",
        "for inps in (inp1,inp2):\n",
        "  if model_1.predict(preprocess(inps))>=.5:\n",
        "    print(\"Predicts LEGAL for {}\".format(inps))\n",
        "  else:\n",
        "    print(\"Predicts ILLEGAL for {}\".format(inps))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicts ILLEGAL for [['b' 't' 's' 'x' 'x' 'v' 'v' 'e']]\n",
            "Predicts LEGAL for [['b' 't' 'b' 't' 's' 'x' 'x' 'v' 'v' 'e' 't' 'e']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1qS6p02sem9",
        "outputId": "0ad4560e-d2a2-40fe-fdcb-9546374c2a77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_valid_hat_1=[]\n",
        "all_preds_1=model_1.predict(valid_1)\n",
        "for k in all_preds_1:\n",
        "  if k>=.5:\n",
        "    X_valid_hat_1.append(1)\n",
        "  else:\n",
        "    X_valid_hat_1.append(0)\n",
        "\n",
        "\n",
        "confusion_matrix(valid_1_.numpy()[:,-1].astype(np.uint8),X_valid_hat_1)\n",
        "# NB: for this task the model is ok, but for other applications it might be worthy investigating overfitting"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2000,    0],\n",
              "       [   0, 2000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    }
  ]
}