{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "REBER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS5WOxSAkGEI"
      },
      "source": [
        "IN THIS CODE I TRY TO SOLVE REBER GRAMMAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozQD6LwcS37z"
      },
      "source": [
        "PART 1: BUILD THE SIMPLE AND COMPLEX GENERATORS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__hJyOP9oQz2"
      },
      "source": [
        "# Import dependencies\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 1305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C37Ltx9l7R69"
      },
      "source": [
        "# add the character before!\n",
        "def rerun_short(st,go,alt):\n",
        "  no_prefix=0\n",
        "  while st.endswith(alt)==False:\n",
        "    proba=np.random.rand(1)\n",
        "    if proba>=.5:\n",
        "      st+=go\n",
        "    else:\n",
        "      st+=alt\n",
        "    no_prefix+=1\n",
        "  return st[-no_prefix:]"
      ],
      "execution_count": 1306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glhoYhbc2wu_"
      },
      "source": [
        "def rerun_long(st,go_inside=\"t\",alt_inside=\"v\"):\n",
        "  begin=len(st)\n",
        "  while True:\n",
        "    st+=\"x\"\n",
        "    st+=rerun_short(st,go_inside,alt_inside)\n",
        "    proba_=np.random.rand(1)\n",
        "    if proba_>=.5:\n",
        "      st+=\"v\"\n",
        "      break    \n",
        "    else:\n",
        "      st+=\"p\"    \n",
        "  return st[begin:] "
      ],
      "execution_count": 1307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1kZeF0w5UHZ"
      },
      "source": [
        "# Reber grammar-simple generator\n",
        "def simple_generator():\n",
        "  z=\"b\"\n",
        "  proba_1=np.random.rand(1)\n",
        "  if proba_1>=.5:\n",
        "    z+=\"t\"\n",
        "    z+=rerun_short(z,\"s\",\"x\")\n",
        "    proba_2=np.random.rand(1)\n",
        "    if proba_2>=.5:\n",
        "      z+=\"se\"\n",
        "    else:\n",
        "      z+=rerun_long(z)\n",
        "      z+=\"e\"\n",
        "  else:\n",
        "    z+=\"p\"\n",
        "    z+=rerun_short(z,\"t\",\"v\")\n",
        "    proba_3=np.random.rand(1)\n",
        "    if proba_3>=.5: \n",
        "      z+=\"ve\"\n",
        "    else:\n",
        "      z+=\"p\"\n",
        "      z+=rerun_long(z)\n",
        "      z+=\"e\"\n",
        "  return z\n"
      ],
      "execution_count": 1308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOvK5TLjQgmW"
      },
      "source": [
        "# Reber grammar-complex generator\n",
        "def complex_generator():\n",
        "  z=\"b\"\n",
        "  proba=np.random.rand(1)\n",
        "  if proba>=.5:\n",
        "    z+=\"t\"\n",
        "    z+=simple_generator()\n",
        "    z+=\"te\"\n",
        "  else:\n",
        "    z+=\"p\"\n",
        "    z+=simple_generator()\n",
        "    z+=\"pe\"\n",
        "  return z"
      ],
      "execution_count": 1309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByaKtDnIRblr",
        "outputId": "1dc7407a-caae-4a8f-8999-752db3c0e400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "complex_generator()"
      ],
      "execution_count": 1310,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'btbtxxtvpxvvete'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1310
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15i3ZaRIS3LI"
      },
      "source": [
        "PART 2: CREATING THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMgwvlUxRoeW"
      },
      "source": [
        "# Creating a fancy function for illegal words. With the permutations the newly generated set \n",
        "# is not granted to satisfy the grammar rules w.r.t. the order\n",
        "np.random.seed(12)\n",
        "a=simple_generator()\n",
        "k=[element for element in a]\n",
        "g=np.random.permutation(np.array(k))\n",
        "\n"
      ],
      "execution_count": 1311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvvbfS_uvQDa"
      },
      "source": [
        "def complete_set(instances,generator):\n",
        "  max=0\n",
        "  for i in range(instances):\n",
        "    X_true_one=np.array([element for element in generator()])\n",
        "    X_false_one=np.random.permutation(X_true_one)\n",
        "    if len(X_true_one)>max:\n",
        "      max=len(X_true_one)\n",
        "    zero_padding_one=np.zeros((max-len(X_true_one)))\n",
        "    X_true_one=np.concatenate((X_true_one,zero_padding_one))\n",
        "    X_false_one=np.concatenate((X_false_one,zero_padding_one))\n",
        "    if i==0:\n",
        "      X_trues=X_true_one[tf.newaxis,:]\n",
        "      X_falses=X_false_one[tf.newaxis,:]\n",
        "    else:\n",
        "      X_true_one=X_true_one[tf.newaxis,:]\n",
        "      X_false_one=X_false_one[tf.newaxis,:]\n",
        "      if max>X_trues.shape[-1]:\n",
        "        zero_padding_two=np.zeros((len(X_trues),(max-X_trues.shape[-1])))\n",
        "        X_trues=np.concatenate((X_trues,zero_padding_two),axis=1)\n",
        "        X_falses=np.concatenate((X_falses,zero_padding_two),axis=1)\n",
        "      X_trues=np.concatenate((X_trues,X_true_one),axis=0)\n",
        "      X_falses=np.concatenate((X_falses,X_false_one),axis=0)\n",
        "      if i==instances-1:   # attach the labels at the end of the second axis\n",
        "        True_set=np.concatenate((X_trues,np.ones((instances,1))),axis=1)\n",
        "        False_set=np.concatenate((X_falses,np.zeros((instances,1))),axis=1)\n",
        "        return np.concatenate((True_set,False_set),axis=0)  \n"
      ],
      "execution_count": 1312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fHTQU0u0IvD"
      },
      "source": [
        "# NB: this cell is quite slow\n",
        "n_train=5000*2\n",
        "train=np.random.permutation(complete_set(5000,simple_generator))  # creating the dataset and shuffling it the first time"
      ],
      "execution_count": 1313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxsEcuAMIY3j"
      },
      "source": [
        "def preprocess(dataset):\n",
        "  # Since we have a list of strings, we need to tokenize those.\n",
        "  distinct=np.unique(dataset)\n",
        "  # Since we have only seven distinct characters, we can easily convert them manually to integers \n",
        "  new_dataset=np.empty(dataset.shape)\n",
        "  new_dataset=np.reshape(new_dataset,new_dataset.shape[0]*new_dataset.shape[1])\n",
        "  diction={\"0.0\":0,\"1.0\":1,\"b\":2,\"e\":3,\"p\":4,\"s\":5,\"t\":6,\"v\":7,\"x\":8}\n",
        "  for index,element in enumerate(np.reshape(dataset,dataset.shape[0]*dataset.shape[1])):\n",
        "    new_dataset[index]=diction[element]\n",
        "  return tf.constant(new_dataset.reshape(dataset.shape[0],dataset.shape[1]),dtype=tf.float32)\n",
        "  "
      ],
      "execution_count": 1314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL2zaGt_InoZ"
      },
      "source": [
        "train=preprocess(train)"
      ],
      "execution_count": 1315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAPo8atC0cDt"
      },
      "source": [
        "valid_=np.random.permutation(complete_set(2000,simple_generator))"
      ],
      "execution_count": 1316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6JK455FADzU"
      },
      "source": [
        "valid_=preprocess(valid_)"
      ],
      "execution_count": 1317,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOzTi_mG56RW"
      },
      "source": [
        "STEP 3: GO TENSORFLOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiFFl1BI3dxk",
        "outputId": "1864fd44-8389-4236-911c-7dc58fd6e24b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "train=tf.data.Dataset.from_tensor_slices(train)\n",
        "for i in train.take(1):\n",
        "  print(i.numpy())"
      ],
      "execution_count": 1318,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 6. 8. 8. 6. 7. 7. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_GLCJ6NxK6K",
        "outputId": "9eb99e1f-da52-46f0-813e-4081d04bb2ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "batch_size=16\n",
        "train=train.shuffle(500).repeat().batch(batch_size)\n",
        "train=train.map(lambda item:(item[:,:-1],item[:,-1:]))\n",
        "for item in train.take(1):\n",
        "  print(item)  # A tuple containing features and label\n",
        "train=train.prefetch(1)"
      ],
      "execution_count": 1319,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(16, 66), dtype=float32, numpy=\n",
            "array([[2., 6., 5., ..., 0., 0., 0.],\n",
            "       [2., 6., 8., ..., 0., 0., 0.],\n",
            "       [2., 6., 8., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [5., 2., 8., ..., 0., 0., 0.],\n",
            "       [2., 6., 8., ..., 0., 0., 0.],\n",
            "       [8., 7., 2., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
            "array([[1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.]], dtype=float32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwBayS5VBFPS",
        "outputId": "daffd7b0-de80-4a1c-9485-ebc6668aa85d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# for validation data:\n",
        "valid=tf.data.Dataset.from_tensor_slices(valid_)\n",
        "valid=valid.batch(batch_size)\n",
        "valid=valid.map(lambda item:(item[:,:-1],item[:,-1:]))\n",
        "valid.prefetch(1)"
      ],
      "execution_count": 1320,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 57), (None, 1)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1320
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjm1LFom8Oy9"
      },
      "source": [
        "def model_builder(n_units=128):\n",
        "  model=tf.keras.models.Sequential([\n",
        "          tf.keras.layers.Embedding((len(distinct)+1),n_units,input_shape=[None]),\n",
        "          tf.keras.layers.GRU(units=n_units),\n",
        "          tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "        ])\n",
        "  return model"
      ],
      "execution_count": 1321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Watik-hG-Jep",
        "outputId": "b49c6799-2b4b-4f93-ac7f-35c0c71778bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "model=model_builder()\n",
        "model.summary()"
      ],
      "execution_count": 1322,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_17 (Embedding)     (None, None, 128)         1280      \n",
            "_________________________________________________________________\n",
            "gru_29 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 100,481\n",
            "Trainable params: 100,481\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsS-r7nM-Mxm",
        "outputId": "f879cee2-44b4-45b5-be45-a6312ff878a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "source": [
        "opt=tf.keras.optimizers.RMSprop(lr=.01)\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n",
        "history=model.fit(dataset,epochs=15,steps_per_epoch=n_train//batch_size,validation_data=valid)"
      ],
      "execution_count": 1323,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7111 - accuracy: 0.5000 - val_loss: 0.6859 - val_accuracy: 0.5680\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.6701 - accuracy: 0.5893 - val_loss: 0.6830 - val_accuracy: 0.5527\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.4413 - accuracy: 0.7525 - val_loss: 0.0279 - val_accuracy: 0.9960\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0736 - accuracy: 0.9837 - val_loss: 0.0333 - val_accuracy: 0.9960\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0334 - accuracy: 0.9950 - val_loss: 0.0343 - val_accuracy: 0.9958\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0175 - accuracy: 0.9960 - val_loss: 0.0269 - val_accuracy: 0.9965\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0192 - accuracy: 0.9973 - val_loss: 0.0304 - val_accuracy: 0.9967\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0220 - accuracy: 0.9973 - val_loss: 0.0316 - val_accuracy: 0.9967\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0133 - accuracy: 0.9985 - val_loss: 0.0351 - val_accuracy: 0.9965\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0138 - accuracy: 0.9983 - val_loss: 0.0268 - val_accuracy: 0.9962\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0205 - accuracy: 0.9965 - val_loss: 0.0273 - val_accuracy: 0.9965\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 0.0303 - val_accuracy: 0.9967\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0098 - accuracy: 0.9990 - val_loss: 0.0324 - val_accuracy: 0.9965\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.0298 - val_accuracy: 0.9970\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0168 - accuracy: 0.9982 - val_loss: 0.0310 - val_accuracy: 0.9965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXAVsl0p_yVU",
        "outputId": "acea0827-1c81-4126-dede-5098cc36282a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# please feed a 2d array!\n",
        "inp=np.array([[\"b\",\"t\",\"s\",\"x\",\"x\",\"v\",\"v\",\"e\"]])\n",
        "if model.predict(preprocess(inp))>=.5:\n",
        "  print(\"Predicts LEGAL\")\n",
        "else:\n",
        "  print(\"Predicts ILLEGAL\")\n",
        "\n",
        "  "
      ],
      "execution_count": 1326,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicts LEGAL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR6v-Eu2H7KN",
        "outputId": "466cf4ad-f702-48b4-8e84-04de49af2c05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_valid_hat=[]\n",
        "all_preds=model.predict(valid)\n",
        "for k in all_preds:\n",
        "  if k>=.5:\n",
        "    X_valid_hat.append(1)\n",
        "  else:\n",
        "    X_valid_hat.append(0)\n",
        "\n",
        "\n",
        "confusion_matrix(valid_.numpy()[:,-1].astype(np.uint8),X_valid_hat)"
      ],
      "execution_count": 1328,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1986,   14],\n",
              "       [   0, 2000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1328
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLIkSwGZfUaA"
      },
      "source": [
        "STEP 5: FACE THE MORE COMPLEX ONE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2GwRiR0fTWp"
      },
      "source": [
        "# NB: you can drink a coffee whilst waiting this to be executed\n",
        "n_train_1=7500*2\n",
        "train_1=np.random.permutation(complete_set(7500,complex_generator)) \n",
        "train_1=preprocess(train_1)\n",
        "valid_1_=np.random.permutation(complete_set(2000,complex_generator))\n",
        "valid_1_=preprocess(valid_1_)"
      ],
      "execution_count": 1329,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_yUslAlaVWm"
      },
      "source": [
        "train_1=tf.data.Dataset.from_tensor_slices(train_1)\n",
        "train_1=train_1.shuffle(700).repeat().batch(batch_size)\n",
        "train_1=train_1.map(lambda item:(item[:,:-1],item[:,-1:]))\n",
        "train_1=train_1.prefetch(1)"
      ],
      "execution_count": 1330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1bbNYjwiBin"
      },
      "source": [
        "valid_1=tf.data.Dataset.from_tensor_slices(valid_1_)\n",
        "valid_1=valid_1.batch(batch_size)\n",
        "valid_1=valid_1.map(lambda item:(item[:,:-1],item[:,-1:]))\n",
        "valid_1=valid_1.prefetch(1)"
      ],
      "execution_count": 1331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UTa58NkifHq"
      },
      "source": [
        "# Let's create with a model which is similar to the one used before\n",
        "def model_builder_1(n_units=128):\n",
        "  model=tf.keras.models.Sequential([\n",
        "          tf.keras.layers.Embedding((len(distinct)+1),n_units,input_shape=[None]),\n",
        "          tf.keras.layers.GRU(units=n_units),\n",
        "          tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "        ])\n",
        "  return model"
      ],
      "execution_count": 1332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H2UY8x1ipt4"
      },
      "source": [
        "model_1=model_builder_1()"
      ],
      "execution_count": 1333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbpOVkTJiupU",
        "outputId": "0423ddbe-a700-4b48-daba-e0589870f04e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "source": [
        "opt=tf.keras.optimizers.RMSprop(lr=.01)\n",
        "model_1.compile(loss=\"binary_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n",
        "history=model_1.fit(train_1,epochs=15,steps_per_epoch=n_train_1//batch_size,validation_data=valid_1)"
      ],
      "execution_count": 1334,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.0900 - accuracy: 0.9635 - val_loss: 0.1060 - val_accuracy: 0.9987\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0135 - accuracy: 0.9980 - val_loss: 0.0164 - val_accuracy: 0.9970\n",
            "Epoch 3/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0859 - accuracy: 0.9783 - val_loss: 0.0369 - val_accuracy: 0.9937\n",
            "Epoch 4/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0326 - accuracy: 0.9938 - val_loss: 0.0118 - val_accuracy: 0.9980\n",
            "Epoch 5/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0183 - accuracy: 0.9962 - val_loss: 0.0113 - val_accuracy: 0.9987\n",
            "Epoch 6/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0274 - accuracy: 0.9973 - val_loss: 0.0058 - val_accuracy: 0.9990\n",
            "Epoch 7/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0104 - accuracy: 0.9980 - val_loss: 0.0131 - val_accuracy: 0.9983\n",
            "Epoch 8/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0189 - accuracy: 0.9970 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 9/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0103 - accuracy: 0.9987 - val_loss: 0.0016 - val_accuracy: 0.9992\n",
            "Epoch 10/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0081 - accuracy: 0.9990 - val_loss: 0.0030 - val_accuracy: 0.9992\n",
            "Epoch 11/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 5.6822e-07 - val_accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 5.4037e-08 - accuracy: 1.0000 - val_loss: 7.3526e-09 - val_accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0186 - accuracy: 0.9983 - val_loss: 1.7493e-08 - val_accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 6.7980e-09 - accuracy: 1.0000 - val_loss: 6.2691e-09 - val_accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0159 - accuracy: 0.9983 - val_loss: 6.0479e-06 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLGsIlDqq3AX",
        "outputId": "f6304119-608b-48fd-d775-8047e2223907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "inp1=np.array([[\"b\",\"t\",\"s\",\"x\",\"x\",\"v\",\"v\",\"e\"]])    # this was Legal in previous model!\n",
        "inp2=np.array([[\"b\",\"t\",\"b\",\"t\",\"s\",\"x\",\"x\",\"v\",\"v\",\"e\",\"t\",\"e\"]])\n",
        "for inps in (inp1,inp2):\n",
        "  if model_1.predict(preprocess(inps))>=.5:\n",
        "    print(\"Predicts LEGAL for {}\".format(inps))\n",
        "  else:\n",
        "    print(\"Predicts ILLEGAL for {}\".format(inps))  \n",
        "\n",
        "\n"
      ],
      "execution_count": 1335,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicts ILLEGAL for [['b' 't' 's' 'x' 'x' 'v' 'v' 'e']]\n",
            "Predicts LEGAL for [['b' 't' 'b' 't' 's' 'x' 'x' 'v' 'v' 'e' 't' 'e']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NGptfcujJg-",
        "outputId": "b55d3e5a-6540-400f-d7b3-f8bb506e61b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_valid_hat_1=[]\n",
        "all_preds_1=model_1.predict(valid_1)\n",
        "for k in all_preds_1:\n",
        "  if k>=.5:\n",
        "    X_valid_hat_1.append(1)\n",
        "  else:\n",
        "    X_valid_hat_1.append(0)\n",
        "\n",
        "\n",
        "confusion_matrix(valid_1_.numpy()[:,-1].astype(np.uint8),X_valid_hat_1)"
      ],
      "execution_count": 1336,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2000,    0],\n",
              "       [   0, 2000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1336
        }
      ]
    }
  ]
}